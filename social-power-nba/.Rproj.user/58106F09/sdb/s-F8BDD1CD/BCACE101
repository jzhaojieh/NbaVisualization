{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Homework 4\"\nauthor: \"Dylan Hyun (dchyun)\"\ndate: \"2/15/2018\"\noutput: pdf_document\n---\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE)\nlibrary(np)\nlibrary(knitr)\nlibrary(kableExtra)\n```\n\n## 1. \n  \n**C.**\n  \n```{r}\ndata = read.table(\"CASE1201.ASC\", header = TRUE)\nattach(data)\nnewdata = data[order(-rank),]\nnewdata[1:50,]\nrm = lm(sat~takers+rank, data=data)\nresiduals = residuals(rm)\nres = data.frame(data$state, residuals, data$rank)\nattach(res)\nres[order(-residuals),]\n```\n  \nConnecticut and Mississippi had the biggest changes in ranking. Connecticut rose from 49th to 1st, and Mississippi fell from 2nd to 46th. This was due to the fact that Mississippi had such a small percentage of people take the test, only 3%, even if it did have a high ranking from that 3%, above 90%. Connecticut on the other hand had a huge number of people take the test, 69%, and still managed to get a ranking score of 69.8%. \n  \n**D.**\n  \n```{r}\nplot(data$takers, residuals(rm), xlab=\"Percentage of Test Takers\", ylab = \"Prediction Error (SAT Score)\")\nplot(data$rank, residuals(rm), xlab=\"Rank\", ylab = \"Prediction Error (SAT Score)\")\n```\n  \nThe plots for both variables appear to satisfy the assumption of the model. The residuals are evenly spread around 0, and have constant variance for every x. The only issue that can be seen is that there do appear to be some outliers. There are several data points that have extremely low residual values.\n  \n**E.**\n  \nFrom the residual plots, it doesn't appear that any varaible transformations would be useful. It may be useful to remove some of the outliers that can be seen on both residual plots. It could possible be useful to include either data on income or expenditures. It may not be necessary to include both, as it can be infered that if a state has high income, they will have higher expenditures as well. It may also be interesting to contorl for public school percentage, as this seems to vary widely between states. \n  \nModel Proposed:\n$$SAT = Rank + Takers + Expenditures + Public$$\n  \n**F.**\n  \nIt appears that in states where takers is below 20, that the SAT score is noticibly higher, either in the 900's or 1000's. For states with takers above 30, their SAT score is much lower, typically in the 800's. A model that could possible account for this difference would be one that uses kerenal regression on the variables takers and rank. \n  \n## 2.\n  \n**A.**\n  \n```{r}\nhouse.train = read.csv(\"housetrain.csv\")\nhouse.test = read.csv(\"housetest.csv\")\nplot(house.train$Longitude, house.train$Latitude, pch = \".\")\n```\n  \nThe clusers appear to be for the states California and Pennsylvania. \n  \n**B.**\n  \n```{r}\npar(mfrow=c(2,2))\nm3 = lm(Median_house_value~Median_household_income+Mean_household_income, data=house.train)\nplot(house.train$Latitude, residuals(m3), ylab = \"Prediction Error (House Value)\", xlab = \"Latitude\")\nplot(house.train$Longitude, residuals(m3), ylab = \"Prediction Error (House Value)\", xlab = \"Longitude\")\n```\n  \nYes it appears location could be useful in predicting house value, because the residuals have distinct patterns that show location is an influential pattern in predicting house value. For instance, the current model constantly over-predicts the price of houses at low longitudes (California), and under-predicts the price of homes at higher longitudes (Pennsylvania).\n  \n**C.**\n  \n```{r}\npar(mfrow=c(2,2))\nm4 = lm(Median_house_value~Median_household_income+Mean_household_income+Latitude+Longitude, data=house.train)\nplot(residuals(m4), house.train$Median_household_income, xlab = \"Prediction Error (House Value)\", ylab = \"Median Income\")\nplot(residuals(m4), house.train$Mean_household_income, xlab = \"Prediction Error (House Value)\", ylab = \"Mean Income\")\nplot(house.train$Latitude, residuals(m4), ylab = \"Prediction Error (House Value)\", xlab = \"Latitude\")\nplot(house.train$Longitude, residuals(m4), ylab = \"Prediction Error (House Value)\", xlab = \"Longitude\")\nplot(fitted.values(m4), residuals(m4), ylab = \"Prediction Error (House Value)\", xlab = \"Fitted Values\")\n```\n  \nModel 3 still appears to be the beter fit for the model, because the residuals for Longitude are still breaking the linear model assumptions. The model is still over-predicting price for CA and under-predicting for PA. \n  \n**D.**\n  \n```{r}\nn = 5303\nm5 = npreg(bws=apply(house.train[,c(5,6)],2,sd)/n^(0.2), residuals = T, xdat = house.train[,c(5,6)], ydat = house.train$Median_house_value)\nm6 = npreg(bws=apply(house.train[,c(5,6,2,3)],2,sd)/n^(0.2), residuals = T, xdat = house.train[,c(5,6,2,3)], ydat = house.train$Median_house_value)\nplot(m5$mean, m5$resid, ylab = \"Prediction Error (Median House Value)\", xlab = \"Fitted Values\")\nplot(m6$mean, m6$resid, ylab = \"Prediction Error (Median House Value)\", xlab = \"Fitted Values\")\n```\n  \nThe residulas appear to satisfy all the assumptions. They are evenly spread around 0 for every x, and appear patterless, and have constant variance. \n  \n**E.**\n  \n```{r}\nhouse.data=rbind(house.train,house.test)\nsamp=sample(rep(1:5,2121),replace=F)\n\nerrors = matrix(nrow = 5, ncol = 4)\n\nset.seed(1)\nK = 5\nfold.assignments = rep(1:K,length=n)\nfold.assignments = sample(fold.assignments)  # assign each pt to a fold, at random\n\n# Perform cross-validation\n  samp=sample(rep(1:5,2121),replace=F)\n  for(k in 1:5){\n    testd=house.data[samp==k,]\n    traind=house.data[!(samp==k),]\n    \n    for (d in 0:3) {\n      # Fit model\n      if (d == 0) {\n        m3 = lm(Median_house_value~Median_household_income+Mean_household_income, data=traind)\n        pred = predict(m3, testd)\n        errors[k,1] = mean((testd$Median_house_value-pred)^2)\n      }\n      if (d == 1){\n          m4 = lm(Median_house_value~Median_household_income+Mean_household_income\n                     +Latitude+Longitude, data=traind)\n          pred = predict(m4, testd)\n          errors[k,2] = mean((testd$Median_house_value-pred)^2)\n      }\n      if (d == 2){\n          m5=npreg(Median_house_value~Median_household_income+\n                      Mean_household_income,data=traind,newdata=testd,\n                      bws=apply(traind[,c(5,6)],2,sd)/n^(0.2))\n          errors[k,3] = mean((testd$Median_house_value-m5$mean))\n      }\n      if (d == 3){\n          m6=npreg(Median_house_value~Median_household_income+\n                      Mean_household_income+Latitude+Longitude,data=traind,newdata=testd,\n                      bws=apply(traind[,c(5,6,2,3)],2,sd)/n^(0.2))\n          errors[k,4] = mean((testd$Median_house_value-m6$mean))\n      }\n    }\n  }\n```\n  \n**F.**\n  \n```{r}\nAvg_Error = colMeans(errors)\nSE = apply(errors,2,sd)/sqrt(K)\nModels = c(\"M3\", \"M4\", \"M5\", \"M6\")\nkable(data.frame(Models, Avg_Error, SE), caption = \"Errors\")\n```  \n  \nThe table shows that the models computed using kerenal regression are clearly better than the linear models. The model with the smallest SE, model 6, has a SE that is 0.46 smaller than the SE of model 5. This shows that adding latitude and longitude to the model does reduce the overall error, but when using kerenal regression the difference isn't as large as it might be expected to be. ",
    "created" : 1520390919027.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3799576325",
    "id" : "BCACE101",
    "lastKnownWriteTime" : 1518803684,
    "last_content_update" : 1518803684,
    "path" : "~/Documents/College/17/Spring/Regression/hw4.Rmd",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 5,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}