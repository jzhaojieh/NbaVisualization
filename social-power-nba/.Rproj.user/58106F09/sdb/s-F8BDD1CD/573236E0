{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Exam 1\"\nauthor: \"Dylan Hyun (dchyun)\"\ndate: \"3/7/2018\"\noutput: pdf_document\n---\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE)\nlibrary(np)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(MASS)\n```\n\n#1. \n  \n**A.**\n  \n```{r}\npar(mfrow=c(2,2))\nabalone = read.csv(\"abalonemt.csv\")\nplot(abalone$Diameter,abalone$Shucked.weight\n     , xlab=\"Diameter (mm)\", ylab=\"Shucked Weight (g)\", pch=20, col=\"lightblue3\")\nplot(abalone$Length,abalone$Shucked.weight\n     , xlab=\"Length (mm)\", ylab=\"Shucked Weight (g)\",pch=20, col=\"lightblue3\")\nplot(abalone$Height,abalone$Shucked.weight\n     , xlab=\"Height (mm)\", ylab = \"Shucked Weight (g)\",pch=20, col=\"lightblue3\")\n```\n  \nIt appears that for every predictor as the predictor increses, the shucked weight increases as well. For all three predictors the relationship with shucked weight appears to be possibly exponential, though most notibly for Diameter and Length. \n  \n**B.**\n  \n```{r, fig.height=3}\npar(mfrow=c(1,3))\nm1 = lm(log(abalone$Shucked.weight)~log(abalone$Diameter)+\n          log(abalone$Length)+log(abalone$Height))\nm2 = smooth.spline(abalone$Shucked.weight~abalone$Diameter+\n                     abalone$Length+abalone$Height)\nm3 = npreg(bws=apply(abalone[,c(2,3,4)],2,sd)/length(abalone)^(0.2),\n           residuals = T, xdat = abalone[,c(2,3,4)], ydat = abalone$Shucked.weight)\n\nm1.fitted = exp(predict(m1))\nm2.fitted = predict(m2, x = abalone$Diameter+abalone$Length+abalone$Height)$y\n\nplot(abalone$Diameter+abalone$Length+abalone$Height, m1.fitted,\n     xlab = \"Predictor Variables\", ylab=\"Fitted Values\",\n     main = \"Linear Model\", pch=20, col=\"lightblue3\")\nplot(abalone$Diameter+abalone$Length+abalone$Height, m2.fitted,\n     xlab = \"Predictor Variables\", ylab=\"Fitted Values\",\n     main = \"Smooth Spline\", pch=20, col=\"lightblue3\")\nplot(abalone$Diameter+abalone$Length+abalone$Height, m3$mean,\n     xlab = \"Predictor Variables\", ylab=\"Fitted Values\",\n     main = \"Kernel Regression\", pch=20, col=\"lightblue3\")\n```\n  \nThe predictors all seems to be very similar when looking at the plot of the fitted values. All three seems to have exponential relationships with the fitted values. \n  \n```{r}\npar(mfrow=c(2,2))\nplot(abalone$Diameter+abalone$Length+abalone$Height, residuals(m1),\n     ylab=\"Prediction Error (Shucked Wt)\", xlab=\"Predictor Variables\",\n     main = \"M1 Residuals vs. Predictors\", pch=20, col=\"lightblue3\")\nplot(abalone$Diameter+abalone$Length+abalone$Height, residuals(m1)^2,\n     ylab=\"Prediction Error (Shucked Wt) Sq\", xlab=\"Predictor Variables\",\n     main = \"M1 Residuals Sq vs. Predictors\", pch=20, col=\"lightblue3\")\nhist(residuals(m1), breaks = 75,  xlab=\"Prediction Error (Shucked Wt)\",\n     main = \"Histogram of M1 Residuals\", pch=20, col=\"lightblue3\")\nqqnorm(residuals(m1),pch=20,col=\"lightblue3\")\nqqline(residuals(m1),pch=20,col=\"lightblue3\")\n\nplot(abalone$Diameter+abalone$Length+abalone$Height, residuals(m2),\n     ylab=\"Prediction Error (Shucked Wt)\", xlab=\"Predictor Variables\",\n     main = \"M2 Residuals vs. Predictors\", pch=20, col=\"lightblue3\")\nplot(abalone$Diameter+abalone$Length+abalone$Height, residuals(m2)^2,\n     ylab=\"Prediction Error (Shucked Wt) Sq\", xlab=\"Predictor Variables\",\n     main = \"M2 Residuals Sq vs. Predictors\", pch=20, col=\"lightblue3\")\nhist(residuals(m2), breaks = 75,xlab=\"Prediction Error (Shucked Wt)\",\n     main = \"Histogram of M2 Residuals\", pch=20, col=\"lightblue3\")\nqqnorm(residuals(m2),pch=20,col=\"lightblue3\")\nqqline(residuals(m2),pch=20)\n\nplot(abalone$Diameter+abalone$Length+abalone$Height, m3$resid,\n     ylab=\"Prediction Error (Shucked Wt)\", xlab=\"Predictor Variables\",\n     main = \"M3 Residuals vs. Predictors\", pch=20, col=\"lightblue3\")\nplot(abalone$Diameter+abalone$Length+abalone$Height, residuals(m3)^2,\n     ylab=\"Prediction Error (Shucked Wt) Sq\", xlab=\"Predictor Variables\",\n     main = \"M3 Residuals Sq vs. Predictors\", pch=20, col=\"lightblue3\")\nhist(residuals(m3), breaks = 75, xlab=\"Prediction Error (Shucked Wt)\",\n     main = \"Histogram of M3 Residuals\", pch=20, col=\"lightblue3\")\nqqnorm(residuals(m3),pch=20,col=\"lightblue3\")\nqqline(residuals(m3),pch=20)\n```\n  \nIn examining the residuals of the three models, all three appear to have normally distributed residuals based on the histogram of the residuals. However, the Q-Q plots for model 2 and 3 show major deviations from normality. Model 1 is the only one with constant variance for every x. In model 2 and 3 the variance increases drastically as x increases. It's possible the error distributions could be related to other variables such as Sex. \n  \n**C.**\n  \n```{r}\nn = 4173\nsamp=sample(rep(1:5,834),replace=F)\n\nerrors = matrix(nrow = 5, ncol = 3)\n\nset.seed(1)\nK = 5\nfold.assignments = rep(1:K,length=n)\nfold.assignments = sample(fold.assignments) \n\n  samp=sample(rep(1:5,834),replace=F)\n  for(k in 1:5){\n    testd=abalone[samp==k,]\n    traind=abalone[!(samp==k),]\n    testd.mean = mean(testd$Shucked.weight)\n    \n    for (d in 0:2) {\n      # Fit model\n      if (d == 0) {\n        m1 = lm(log(Shucked.weight)~log(Diameter)+log(Length)+log(Height), data = traind)\n        pred = predict(m1, testd)\n        errors[k,1] = mean((pred-testd.mean)^2)\n      }\n      if (d == 1){\n        x_sample = traind$Diameter+traind$Length+traind$Height\n        y_sample = traind$Shucked.weight\n        m2 = smooth.spline(x_sample,y_sample)\n        x_test = testd$Diameter+testd$Length+testd$Height\n        y = abalone$Shucked.weight\n        pred = predict(m2, x_test)$y\n        errors[k,2] = mean((pred-testd.mean)^2)\n      }\n      if (d == 2){\n        m3 = npreg(Shucked.weight~Diameter+Length+Height, data=traind, newdata=testd, \n                    bws = apply(traind[,c(2,3,4)],2,sd)/n^(0.2), residuals = T)\n        errors[k,3] = mean((m3$mean-testd.mean)^2)\n      }\n    }\n  }\n  \nSE = apply(errors,2,sd)/sqrt(K)\nModels = c(\"LM\", \"Spline\", \"Kernel\")\nkable(data.frame(Models, SE), caption = \"Errors\")\n```\n  \nAccording to the estimates of the standard error, the kerenal regression model appeared to perform best, though the smoothing spline model has only a slightly larger standard error. \n  \n**D.**\n  \n```{r}\nLength = c(600,400,250)\nDiameter = c(500,350,200)\nHeight = c(150,125,140)\nabalone.three = data.frame(Length,Diameter, Height)\n\nmodel = lm(log(Shucked.weight)~Length+Diameter+Height, data = abalone)\n\n# code modeled on BootstrapRegressionExample.pdf on Canvas\nresample = function(x){  \n  sample(x,size=length(x),replace=TRUE)\n}\nsim.abalone.resids <-function(){  \n  new.abalone <- abalone \n  noise <- resample(residuals(model))  \n  new.abalone$Shucked.weight <- fitted(model)+noisereturn(new.abalone)\n}\nresample.data.frame = function(df){\n  return(df[resample(1:nrow(df)),])\n}\nexp.rhats = function(df) {\n  fit = lm(log(Shucked.weight)~Length+Diameter+Height, data = df)\n  return(predict(fit, newdata = abalone.three))\n}\nB=1000\nrhats = matrix(nrow=B,ncol=length(abalone.three))\nfor (i in 1:B) {\n  rhats[i,] = exp.rhats(resample.data.frame(abalone))\n}\nEst_Bias = mean(rhats) - predict(model, newdata= abalone.three)\nEval_Pts = c(\"X1\", \"X2\", \"X3\")\nkable(data.frame(Eval_Pts,Est_Bias))\n```\n  \nSince, the boostrap used involed resampling whole rows of the data, there are not many assumptions made. For instance, the noise doesn't have to be independant of x, the noise doesn't need to be Gaussian, and the linear model doesn't need to be right. \n  \nA possible explanation for the differences is the biases for the three evaluation points could be that as Length and Diameter increase the model over-predicts the Shucked.weight. Another possibility is that the model has a stronger bias for predictors that are further from the mean of the predictors. \n  \n\\newpage\n#2.\n  \n**A.**\n  \n```{r}\npar(mfrow=c(2,2))\ncats.lm = lm(Hwt~Bwt, data = cats)\ncats.m = cats[cats$Sex == \"M\",]\ncats.m.resid = c()\ncats.f = cats[cats$Sex == \"F\",]\ncats.f.resid = c()\n\nfor (i in (1:144)) {\n  if (cats[i,1] == \"F\") {\n    cats.f.resid = c(cats.f.resid, residuals(cats.lm)[i])\n  }\n  if (cats[i,1] == \"M\") {\n    cats.m.resid = c(cats.m.resid, residuals(cats.lm)[i])\n  }\n}\n\nplot(cats.m$Bwt, cats.m.resid, xlab=\"Body Weight (kg)\",\n     ylab = \"Prediction Error (Heart Wt)\",\n     main = \"Male Residuals vs Body Wt\", pch=20,col=\"lightblue3\")\nqqnorm(cats.m.resid, pch=20,col=\"lightblue3\")\nqqline(cats.m.resid, pch=20)\n\nplot(cats.f$Bwt, cats.f.resid,xlab=\"Body Weight (kg)\",\n     ylab = \"Prediction Error (Heart Wt)\",\n     main = \"Female Residuals vs Body Wt\", pch=20,col=\"lightblue3\")\nqqnorm(cats.f.resid, pch=20,col=\"lightblue3\")\nqqline(cats.f.resid, pch=20)\n```\n  \nThe residuals for male and female appear to be normally distributed. The males appear to have constant variance, though for the females it may appear to decreases as body weight decreases. This could also be due to lack of data for female cats that large. \n  \n```{r, fig.height=3}\npar(mfrow=c(1,2))\nhist(cats.m$Bwt, breaks = 5, xlab=\"Body Weight (kg)\",\n     main = \"Histogram of Male Body Wt\", pch=20, col=\"lightblue3\")\nhist(cats.f$Bwt, breaks = 5, xlab=\"Body Weight (kg)\",\n     main = \"Histogram of Female Body Wt\", pch=20, col=\"lightblue3\")\n```\n  \nThe histograms of the emperical distributions show that the male weights are fairly normally distributed. However, the female weights do not appear to be normally distributed. They appear to be skewed to the right. \n  \n**B.**\n  \n```{r}\ncats.m.lm = lm(cats.m$Hwt~cats.m$Bwt)\ncats.f.lm = lm(cats.f$Hwt~cats.f$Bwt)\n\nn = length(cats)\nnm = length(cats.m)\nnf = length(cats.f)\n\ntheta.hat.b0 = cats.m.lm$coefficients[1]*(nm/n) + cats.f.lm$coefficients[1]*(nf/n)\ntheta.hat.b1 = cats.m.lm$coefficients[2]*(nm/n) + cats.f.lm$coefficients[2]*(nf/n)\n\nplot(cats$Bwt,cats$Hwt, xlab = \"Body Weight (kg)\",\n     ylab=\"Heart Weight (g)\",\n     main = \"Various Regression Models for Body Wt vs. Heart Wt\", pch=20)\nabline(cats.lm)\nabline(cats.f.lm, col = \"pink\")\nabline(cats.m.lm, col = \"blue\")\nabline(theta.hat.b1,theta.hat.b0, col = \"green\")\n```\n  \nFrom the graph it appears that the female regression line would be best for making predictions at smaller body weights. At larger weights it appears that the male regression line is best. At intermediate weights, the casual regression line could be the best predictor. \n  \n**C.**\n  \n```{r}\nB = 1000\ntstars = rep(0,B)\ntobs = 0\nfor (i in (1:B)) {\n  m.resid.sample = sample(cats.m.resid,nm, replace = TRUE)\n  x_m.sample = sample(cats.m$Bwt,nm, replace = TRUE)\n  f.resid.sample = sample(cats.f.resid,nf, replace = TRUE)\n  x_f.sample = sample(cats.m$Bwt,nm, replace = TRUE)\n  \n  y_m.sample = x_m.sample+m.resid.sample\n  y_f.sample = x_f.sample+f.resid.sample\n  \n  cats.m.sample.lm = lm(y_m.sample~x_m.sample)\n  cats.f.sample.lm = lm(y_f.sample~x_f.sample)\n  \n  tstar = (cats.m.sample.lm$coefficients[1] - cats.f.sample.lm$coefficients[1])^2 +\n    (cats.m.sample.lm$coefficients[2] - cats.f.sample.lm$coefficients[2])^2\n  tstars[i] = tstar\n}\np = 1 - length(which(tstars>=tobs))/B\nprint(p)\n```\n  \nIf $\\alpha = 0.05$ then there is evidence to support rejecting $H_0: \\beta_{0,\\text{Male}} = \\beta_{0,\\text{Female}}$ and $\\beta_{1,\\text{Male}} = \\beta_{1,\\text{Female}}$, since $(p = 0.008) <= (\\alpha=0.05)$\n\n",
    "created" : 1520305201064.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1559876488",
    "id" : "573236E0",
    "lastKnownWriteTime" : 1520540281,
    "last_content_update" : 1520540281053,
    "path" : "~/Documents/College/17/Spring/Regression/exam_1.Rmd",
    "project_path" : null,
    "properties" : {
        "last_setup_crc32" : "F36E7EA6656627aa"
    },
    "relative_order" : 6,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}